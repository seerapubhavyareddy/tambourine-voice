# ============================================================================
# Tambourine Server Configuration
# ============================================================================
# Copy this file to .env and fill in your actual API keys
# At least one STT provider and one LLM provider are required
# ============================================================================

# ----------------------------------------------------------------------------
# Speech-to-Text (STT) Providers - At least one required
# ----------------------------------------------------------------------------

# Speechmatics
# https://portal.speechmatics.com
# SPEECHMATICS_API_KEY=your_speechmatics_api_key_here

# AssemblyAI
# https://www.assemblyai.com
# ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here

# Cartesia Ink-Whisper
# https://cartesia.ai
# CARTESIA_API_KEY=your_cartesia_api_key_here

# Deepgram
# https://console.deepgram.com
# DEEPGRAM_API_KEY=your_deepgram_api_key_here

# AWS Transcribe
# https://aws.amazon.com/transcribe
# AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
# AWS_REGION=us-east-1

# Azure Speech
# https://azure.microsoft.com/en-us/products/ai-services/speech-services
# AZURE_SPEECH_KEY=your_azure_speech_key_here
# AZURE_SPEECH_REGION=eastus

# OpenAI Whisper (uses OpenAI API key)
# https://platform.openai.com
# Set OPENAI_API_KEY below to enable

# Google Speech (uses Google service account)
# https://cloud.google.com/speech-to-text
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Groq (uses Groq API key)
# https://console.groq.com
# Set GROQ_API_KEY below to enable

# Local Whisper (no API key required)
# Runs locally using faster-whisper
# Enabling this will download the Whisper model on first run
# WHISPER_ENABLED=false
# Optional: device used by local Whisper (cpu|cuda). If unset, pipecat's default is used. Example:
# WHISPER_DEVICE=cuda
# Optional: Whisper model to use locally (e.g., tiny, base, small, medium, large).
# If unset, pipecat's default is used.
# WHISPER_MODEL=medium

# Nemotron ASR
# Run locally or deploy to cloud. See: https://github.com/pipecat-ai/nemotron-january-2026
# NEMOTRON_ASR_URL=ws://localhost:8080/

# ----------------------------------------------------------------------------
# Large Language Model (LLM) Providers - At least one required
# ----------------------------------------------------------------------------

# OpenAI
# https://platform.openai.com
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: for OpenAI-compatible endpoints

# Google Gemini
# https://aistudio.google.com/apikey
# GOOGLE_API_KEY=your_google_api_key_here

# Anthropic
# https://console.anthropic.com
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Cerebras
# https://cloud.cerebras.ai
# CEREBRAS_API_KEY=your_cerebras_api_key_here

# Groq
# https://console.groq.com
# GROQ_API_KEY=your_groq_api_key_here

# Google Vertex AI (uses Google service account)
# https://cloud.google.com/vertex-ai
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Ollama (local, requires base URL and model to enable)
# https://ollama.ai
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2

# OpenRouter
# https://openrouter.ai
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# AWS Bedrock
# https://aws.amazon.com/bedrock
# AWS_BEDROCK_MODEL_ID=your_bedrock_model_id_here  # Required to enable Bedrock
# AWS_ACCESS_KEY_ID=your_aws_access_key_id_here    # Optional (uses default AWS SDK chain if unset)
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here # Optional (uses default AWS SDK chain if unset)
# AWS_SESSION_TOKEN=your_aws_session_token_here    # Optional (temporary credentials)
# AWS_REGION=us-east-1                              # Optional (defaults to AWS SDK settings)
# AWS_PROFILE=default                           # Optional (specify AWS CLI profile)

# ----------------------------------------------------------------------------
# Auto Provider Selection (Optional)
# ----------------------------------------------------------------------------
# When the client sends "auto" as the provider, these settings determine
# which provider to actually use. If not set, the server will use pipecat's default.
# AUTO_STT_PROVIDER=deepgram
# AUTO_LLM_PROVIDER=cerebras

# ----------------------------------------------------------------------------
# Server Configuration (Optional)
# ----------------------------------------------------------------------------
# HOST=127.0.0.1
# PORT=8765

# ----------------------------------------------------------------------------
# Logging Configuration (Optional)
# ----------------------------------------------------------------------------
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# Silero VAD Configuration (Optional)
# ----------------------------------------------------------------------------
# Configure the Silero VAD analyzer (leave unset to use library defaults)
# Supported sample rates: 8000 or 16000
# VAD_CONFIDENCE=0.7     # Confidence threshold (0.0 - 1.0)
# VAD_START_SECS=0.2     # Seconds of speech required to start speaking
# VAD_STOP_SECS=0.8      # Seconds of silence required to stop speaking
# VAD_MIN_VOLUME=0.6     # Minimum audio volume threshold (0.0 - 1.0)
